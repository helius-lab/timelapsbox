# 5. Анализ параметров обработки (ffmpeg и сопутствующие инструменты)

Вторая часть проекта – отложенная обработка – столь же важна для достижения «кинематографичности». Здесь мы рассмотрим параметры ffmpeg и других средств обработки, влияющих на качество: частота кадров финального видео, параметры кодирования (CRF), фильтры (стабилизация, цветокоррекция, виньетка, LUT и др.). Будет описана планируемая pipeline обработки и обоснование выбора настроек.

## 5.1 Частота кадров (FPS) итогового видео

Как упоминалось, целевой FPS = 24 кадра/с для придания киношного характера. В исследовании мы:
* Проверим, как 24fps субъективно воспринимается на снятом материале. Возможно, для очень быстрых движений 24fps покажется слишком «рывковым». Тогда можем увеличить до 30fps. Но обычно, при наличии должного смаза (motion blur), 24fps выглядит плавно.
* Рассмотрим требования воспроизведения: 24fps совместимо со всеми дисплеями (на 60 Гц будет 3:2 кадра, что нормально). 30fps – ещё более плавно, но слегка видео-шный вид. 60fps или выше – дадут супер-гладкость, но это уже не «timelapse» ощущение, а как ускоренное реальное видео. Поэтому маловероятно, что потребуется >30fps.
* Эксперименты: Можно собрать короткий клип в 24fps и тот же материал в 30fps для сравнения, показать коллегам или получить субъективные отзывы. Также обратим внимание, что если кадры снимались слишком редко, 24fps может ускорить движение чересчур. Но это больше вопрос интервала.
* Итогом, скорее всего, фиксируем 24fps как стандарт. Если потребуется соответствие европейским видео стандартам – 25fps (разница незначительна). Возможно, упомянем, что ffmpeg позволяет легко переключать FPS, так что пользователь TimelapseBox сможет сам задать.

Вывод в отчёте: Рекомендованная частота кадров 24 (или 25) fps для достижения плавного кинематографичного движения. Это подкреплено источниками и традицией кино, а также тем, что видео – это серия кадров ~24 в секунду.

## 5.2 Выбор кодека и качество сжатия (CRF)
* Формат кодирования видео: ffmpeg по умолчанию у нас использует H.264 (libx264), что является хорошим выбором: широко совместим и даёт высокое качество при относительно небольших размерах. Альтернатива – H.265/HEVC (сэкономит место ~30% при том же качестве, но дольше кодировать, и на старых устройствах хуже играет) или VP9/AV1 (ещё эффективнее, но ещё медленнее и не так совместимо). Скорее всего, остановимся на H.264 для удобства, возможно, предложим H.265 как опцию для энтузиастов.
* Параметр CRF (Constant Rate Factor) – это ключевой настрой качества в x264. Диапазон 0–51, где 0 = lossless, 23 = стандарт, 18 = визуально без потерь. Мы проведём тесты качества vs размер:
  * Кодирование фрагмента с разными CRF (например, 18, 20, 23, 28) и оценка визуально и через SSIM.
  * Известно, что ~CRF 18 даёт практически неотличимое от оригинала качество. Так и есть: CRF 18 считается визуально lossless. Мы, вероятно, примем CRF = 18 для мастер-видео (чтобы сохранить все детали и не вносить заметных артефактов). Для случаев экономии места можно увеличить до 20–22, но риск появления лёгкой размытости текстур или блоков на однородных областях.
* Также можем упомянуть preset: x264 preset=slower/veryslow может чуть улучшить сжатие (но Pi ограничен в мощности, поэтому, возможно, использовать medium или slow preset).
* Если видео генерируется на более мощном ПК в отложенной обработке, можно и veryslow preset – это детали реализации.
* Цветовое пространство и битность: чтобы видео корректно воспроизводилось, зададим -pix_fmt yuv420p (8-бит, 4:2:0) при кодировании, т.к. это стандарт для H.264 видео. RAW-фото могут быть 12-14 бит, но финальное видео всё равно SDR 8-бит. Если цель – супер-качество, можно рассмотреть HDR 10 (x265), но это выходит за рамки текущих требований (и мало где будет воспроизводиться как надо).
* Аудио: в таймлапсе аудио обычно нет (если не накладывать музыку). ffmpeg-скрипт будет генерировать без звука, или можно добавить фоновую музыку отдельно. Это не основной фокус исследования, поэтому аудио часть кратко: скорее всего, отключаем аудио стрим или оставляем пустым.

Выводы: в отчёте будет рекомендовано: кодек H.264, CRF ~18 для практически безупречного качества, формат цвета yuv420p для совместимости. При необходимости – H.265 с CRF ~20 для ещё лучшей компрессии. Также отметим, что высокое качество кодирования имеет смысл: нет смысла снимать в RAW, делать сложную цветокоррекцию, а потом всё испортить сильным сжатием. Поэтому чуть больший размер файла оправдан.

## 5.3 Стабилизация видео

Стабилизация нужна, если кадры таймлапса имеют нежелательные сдвиги. В идеале, TimelapseBox жёстко закреплён, но на очень долгих съёмках могут быть:
* Вибрации от ветра, техники.
* Небольшие изменения кадрирования, если крепление "дышит" от температуры.
* Удары или случайные смещения (птица села, человек тронул, и т.п.).

Для устранения дрожания используем подход «цифровая стабилизация»:
* В ffmpeg есть библиотека vid.stab, подключаемая фильтром vidstabdetect и vidstabtransform. Она анализирует видео, вычисляет траекторию смещения, и затем выравнивает её. Преимущество – полностью автоматический процесс, достаточно 2-х команд (анализ и применение).
* Однако, по состоянию системы: возможно, на Raspberry Pi ffmpeg собран без vid.stab. Нужно проверить. Если отсутствует, есть два пути: либо перекомпилировать ffmpeg с видстабом (что трудоёмко на Pi), либо использовать альтернативы:
  * VirtualDub Deshaker (Windows, offline).
  * Adobe After Effects Warp Stabilizer (не open-source, но хороший результат).
  * Hugin align_image_stack – интересный подход для таймлапсов, где кадры как фото выравниваются (Retired Engineer blog предлагает через Hugin-библиотеки) – но это тоже требует пост-обработки на ПК.
* Мы постараемся применить ffmpeg+vidstab. Возможно, для удобства перенесём кадры на PC и там стабилизируем, чтобы не мучить Pi. Стабилизация будет опциональной: применять только если действительно есть проблема. Избегаем стабилизации, когда камера двигалась намеренно (например, если мы сделали motion-timelapse и прикрутили моторизированный слайдер – тогда дрожание минимально, а движение нужно сохранить).
* Режимы стабилизации: настроим параметры vid.stab, если будем использовать: shakiness, smoothing – скорее всего по умолчанию, либо увеличим плавность если нужно. В отчёте опишем, что стабилизация улучшила видео – покажем кадр «до» (дрожащий горизонт, допустим) и «после» (ровная линия). Укажем, что за это пришлось заплатить обрезкой краёв (можно рассчитать сколько пикселей потеряно, или задать видстабу опцию заполнения краёв размытим).
* Примечание о движении камеры: Если в будущем хотим добавлять панорамирование/наклон (например, с помощью Syrp Genie или самодельного моторчика), таймлапс становится motion-lapse. Тогда стабилизация нужна в меньшей степени, если система хорошая. Но это вне текущего плана – возможно, в улучшениях упомянем.

В результате этого подраздела: методика стабилизации с помощью ffmpeg vid.stab будет включена в документацию. Ссылкой отметим, что ffmpeg действительно имеет модуль стабилизации. И сделаем вывод: рекомендуется обеспечить механическую стабильность на этапе съемки; при постобработке стабилизацию применять при необходимости, так как она кропает изображение и может слегка размыть кадры.

## 5.4 Фильтры пост-обработки для художественного эффекта

Здесь перечислим ключевые фильтры и эффекты, которые будут использоваться для улучшения эстетики таймлапса. Реализация фильтров планируется через ffmpeg (что позволяет автоматизировать в скрипте), но некоторые вещи могут делаться и при подготовке RAW (например, коррекция экспозиции, контраста в Lightroom, затем экспорт в TIFF/JPEG и склейка ffmpeg'ом). Мы опишем как, но упор на ffmpeg как универсальный инструмент.

* **Deflicker (устранение мерцания)** – Первейший фильтр для таймлапсов. В ffmpeg нет прямого deflicker-фильтра по состоянию на сейчас, но пути решения:
  * Использовать сторонний инструмент: например, LRTimelapse (связка с Lightroom) – коммерческий, но мощный, выравнивает экспозицию между кадрами по сглаженной кривой.
  * Использовать Neat Video плагин, который умеет убирать flicker, работая как пост-обработка в After Effects/Premiere.
  * Написать скрипт на Python/OpenCV: считать среднюю яркость каждого кадра, и выровнять по скользящему среднему.
  
  В контексте TimelapseBox, хотелось бы автоматизации. Возможно, simplest: добавить в ffmpeg фильтр minterpolate (иногда для промежуточных кадров, но не то) или постоянная экспозиция: если все кадры снимались с одинаковыми настройками, flicker минимален. Он может возникнуть из-за авто-экспозиции или непостоянства диафрагмы. Мы уже снизили эти причины. Поэтому скорее всего, deflicker не понадобится сильно, кроме случаев day-to-night. Но мы заложим опцию: либо интеграция с LRTimelapse workflow (RAW->Lightroom->LRT deflicker->export), либо, для open-source пути, изучим ffmpeg + frei0r-deflicker (есть плагин frei0r). В отчёте отметим, что отсутствие мерцания – одно из главных требований качества, и что мы предприняли (мануальная камера настройка + опциональная софт-коррекция).

* **Цветокоррекция и LUT** – чтобы таймлапс выглядел как «кино», применяем цветовую градацию. План:
  * Выполнить цветокоррекцию на референсном кадре в фоторедакторе (например, взять один RAW кадр, открыть в Lightroom: поправить экспозицию, контраст, кривые, цвета так, чтобы картинка стала выразительной – например, подчеркнуть цвета заката, добавить контраста в облаках, придать теням лёгкий сине-фиолетовый оттенок, как делают в кино).
  * Затем сохранить эти настройки как LUT. Благодаря ffmpeg, мы можем генерировать Hald CLUT изображение, отредактировать его и применить ко всему видео. Конкретно: ffmpeg командой создаёт PNG с сеткой цвета + кадр, мы в Photoshop применяем те же настройки, сохраняем, а потом ffmpeg фильтр haldclut накладывает эту цветокоррекцию на все кадры. Это позволит автоматически применить единый стиль ко всему видео.
  * Если LUT-файл уже имеется (например, кинопрофиль Rec.709->"Blockbuster" стиль), ffmpeg тоже может применить 3D LUT (-vf lut3d=file.cube). Мы можем испытать несколько готовых LUT'ов (они доступны в интернете, например под логарифмические профили камер, или творческие пресеты).
  
  Основные корректировки, которые ожидаются:
  * Кривые (Curves): увеличение контраста S-образной кривой, чтобы изображение не было «плоским». Подчеркивание облаков, структуры.
  * Цветовая температура: возможно, слегка потеплее тон, если хотим уютной атмосферы, или холоднее для драматического эффекта – зависит от сюжета.
  * Насыщенность: немного повысить, но без перебора, чтобы цвета были сочные.
  * LUT под кино: напр., популярный teal-orange (сине-теневые, оранжево-кожаные тона) – применять осторожно, только если уместно.
  
  В отчёте отметим, что применение LUT через ffmpeg позволило добиться согласованной цветовой гаммы легко (чтобы читатель мог воспроизвести). Сошлёмся, что ffmpeg отлично поддерживает LUT для цветоградации. Также отметим: все RAW-кадры обрабатывались с одним профилем, никакие авто-коррекции, чтобы сохранить единый стиль.

* **Виньетирование** – затемнение краёв кадра часто используется в кино для фокусировки взгляда на центре. Мы можем добавить лёгкую виньетку. ffmpeg имеет фильтр vignette, который по умолчанию затемняет углы. Нужно подобрать степень (параметры vignette=PI/4:0.5 например) – поэкспериментируем. Сильную виньетку не стоит делать, чтобы не заметно было перехода, достаточно -0.2 EV на краях.
  * Ещё учитывать: объективы сами могут иметь виньетку на открытой диафрагме. Если заметна виньетирование от объектива, либо её скорректировать (компенсировать в RAW-конвертере), либо творчески использовать, усилив чуть. Решение примем после тестов на кадрах.
  * В отчёте: отметим «применён эффект виньетирования для художественности», укажем, что это реализовано фильтром ffmpeg.

* **Резкость и детализация** – При сжатии и особенно при длинной экспозиции может появиться легкое снижение резкости. Можно применить пост-фильтр резкости (unsharp в ffmpeg). Однако, с 4K исходниками, скорее всего, детализация и так высокая. И чрезмерная резкость вызывает ореолы и цифровой вид. Поэтому будем очень аккуратно с этим. Возможно, не будем шарпить финальное видео, полагаясь на исходное качество. Но если заметим мягкость, протестируем небольшое повышение резкости (например, радиус 3, сумма 0.2).
  * Отдельный момент – диффузные эффекты: наоборот, иногда слегка размывают кадр для «dreamy look». Мы вряд ли это будем делать, т.к. хотим чёткие детали (особенно строят, нужно видеть прогресс).

* **Устранение шумов/артефактов** – Если несмотря на низкий ISO остался видимый шум (например, в ночных таймлапсах звездного неба, шум может мерцать), можно использовать ffmpeg-фильтр hqdn3d (High Quality 3D Denoise) или Neat Video. Neat Video – мощный, но не свободный; hqdn3d – базовый фильтр.
  * Возможно, лучше применить шумодав на этапе экспортирования RAW через Lightroom, чем к уже сжатому видео. Мы определимся после анализа кадров.
  * Касательно мерцающего шума: шум сам по себе случайный, но кадровый шум может выглядеть как «зерно» – что даже художественно. Если он не бросается сильно, можем оставить как есть. Но фиксированный CMOS-pattern noise или цветной шум – будем убирать.

* **Прочие фильтры**: ffmpeg позволяет массу эффектов (сепия, градиенты, blur, tilt-shift имитация и т.д.). Мы перечислим лишь те, что осмысленно улучшают картинку. Например:
  * Выпрямление горизонта – если камера чуть криво стояла, можно повернуть изображение (но тогда кроп).
  * Crop/Pan – можно заранее кадрировать кадры (например, если хотим из исходных 3:2 фото сделать 16:9 кадр, выбрав область). Это сделаем во время ffmpeg-сборки (-vf crop=...).
  * Fade in/out – плавное появление/исчезание видео, если потребуется склеить с другими сюжетами.

Конечный pipeline пост-обработки, вероятно, будет выглядеть так:

```
ffmpeg -framerate 24 -pattern_type glob -i "frames/*.jpg" -vf "vignette,haldclut,vidstabtransform=zoom=0:optzoom=0" -c:v libx264 -crf 18 -pix_fmt yuv420p output.mp4
```

(примечание: это упрощённо, фактически нужно два прохода для vidstab: detect отдельно, потом transform с параметрами файла, и haldclut предполагает подготовленный PNG LUT).

В отчёте мы опишем последовательность: сначала применили стабилизацию (если нужно) – получаем выровненные кадры, затем цветокор и виньетка – получаем финальные кадры, потом кодирование. Возможно, для наглядности приведём блок-схему обработки.

## 5.5 Сборка таймлапса (интеграция всего процесса)

Наконец, как это будет интегрировано технически:
* Автоматизация скриптом: В TimelapseBox можно сделать так, что после завершения съёмки серии, устройство либо самостоятельно запускает ffmpeg для сборки видео (как реализовано сейчас: ffmpeg вызывается с параметрами FPS и качеством). Мы расширим этот шаг, добавив наши фильтры (цветокор, и т.д.). Если Pi недостаточно мощный для RAW-обработки, возможно, будет опция «скачать фото и обработать offline». В плане исследования, можно сделать обе опции: протестировать обработку прямо на устройстве (JPEG + LUT ffmpeg, без тяжелых RAW), и обработку на компьютере (RAW -> TIFF -> ffmpeg).
* Метрики качества после сборки: Проверим финальное видео на соответствие метрикам из раздела 3. Например, можно прогнать ffmpeg + -vf signalstats или сторонний скрипт, чтобы выявить где-то вспышки яркости; или вывести график яркости по кадрам. Все эти данные пойдут в отчёт, подтверждая, что достигли равномерности и плавности.
* Хранение видео: Финальный файл, особенно высокого качества, может быть крупным (несколько сотен МБ). TimelapseBox возможно будет выгружать в облако (если есть облачная интеграция). Мы дадим рекомендации: хранить исходные фото и видео, желательно на внешнем носителе или в облаке, чтобы не потерять труд.
* Повторяемость процесса: В документации репозитория опишем шаги, как от отснятых кадров получить видео. Это важно для пользователей проекта.

Таким образом, этот раздел 5 охватывает все технические аспекты ffmpeg-настроек и их влияние на итоговое качество. В отчёте каждый пункт будет подкреплён либо ссылкой на авторитетный источник (например, про CRF 18 как визуально lossless, про LUT в ffmpeg, про vignette-фильтр), либо результатами наших собственных тестов.